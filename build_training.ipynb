{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pulls in text from FIA csv and generates relevant features\n",
    "csvname='CA_PLOT.csv'\n",
    "treename='CA_TREE.csv'\n",
    "fia=pd.read_csv(csvname,usecols=('PLOT','COUNTYCD','LAT','LON','INVYR','PLOT_STATUS_CD'),delimiter=',', dtype=float)\n",
    "trees=pd.read_csv(treename, delimiter=',', usecols=('PLOT','COUNTYCD','SPCD','STATUSCD'),dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#defines tree class for starting at top row of fia (PLOT.csv), also defining emptyspace as nan\n",
    "#0's mean no match between trees and plot csv (i.e. not sampled, plot_status=2,3)\n",
    "#returns array with class for each plot in order of PLOT.csv file\n",
    "def define_tree_class(num) :\n",
    "    i=0\n",
    "    subfia=fia['PLOT']\n",
    "    subtrees=trees['PLOT']\n",
    "    speciesarraycolumn=[]\n",
    "    deathcodecolumn=[]\n",
    "    counter=0\n",
    "    while i < num :\n",
    "        try:\n",
    "            statusarray=(\n",
    "                trees['STATUSCD'][np.where(int(subfia[i])==subtrees)[0]]\n",
    "                )\n",
    "            statusmajority=np.argmax(np.bincount(statusarray))\n",
    "            numdead=float(len(statusarray[statusarray==2]))\n",
    "            numtotal=float(len(statusarray))\n",
    "            deathprop=float(numdead/numtotal)\n",
    "            if deathprop > .8 :\n",
    "                deathcode=1\n",
    "            if deathprop < .7999999 :\n",
    "                deathcode=0\n",
    "            if statusmajority == 3 :\n",
    "                deathcode=2\n",
    "                \n",
    "        except ValueError :\n",
    "                deathcode=0\n",
    "                counter=counter+1\n",
    "        try:\n",
    "            speciesarray=(\n",
    "                trees['SPCD'][np.where(int(subfia[i])==subtrees)[0]]\n",
    "                )\n",
    "            speciescode= np.argmax(np.bincount(speciesarray))\n",
    "            speciesunique= np.unique(speciesarray)\n",
    "            if len(np.where(speciesarray==speciescode)[0])/len(speciesarray) > .8 :\n",
    "                speciescode=1001\n",
    "            else :\n",
    "                speciescode=speciescode\n",
    "        except ValueError:\n",
    "\n",
    "            speciescode=0\n",
    "        speciesarraycolumn=np.append(speciesarraycolumn,speciescode)\n",
    "        deathcodecolumn=np.append(deathcodecolumn,deathcode)\n",
    "        i=i+1\n",
    "    finalclasses=[]\n",
    "    i=0\n",
    "    for number in speciesarraycolumn :\n",
    "        finaldeathcode=deathcodecolumn[i]\n",
    "        if finaldeathcode == 0 :\n",
    "            if 0 < number < 265:\n",
    "                plotclass=1\n",
    "            if number > 264:\n",
    "                plotclass=2\n",
    "            if number < 1:\n",
    "                plotclass=0\n",
    "            if number > 1000:\n",
    "                plotclass=3\n",
    "        if finaldeathcode == 1 :\n",
    "            if 0 < number < 265:\n",
    "                plotclass=4\n",
    "            if number > 264:\n",
    "                plotclass=5\n",
    "            if number < 1:\n",
    "                plotclass=0\n",
    "            if number > 1000:\n",
    "                plotclass=6\n",
    "        if finaldeathcode == 2 :\n",
    "            plotclass=0\n",
    "        finalclasses=np.append(finalclasses,plotclass)\n",
    "        i=i+1\n",
    "    return(finalclasses)\n",
    "    #arrays below can be used to match ids with plotstatus codes to check functionality\n",
    "    #array=np.zeros((num,2))\n",
    "    #array[:,0]=speciesarraycolumn\n",
    "    #array[:,1]=fia['PLOT_STATUS_CD'][0:100]\n",
    "    #print(array)\n",
    "        \n",
    "finalclasses=define_tree_class(50)\n",
    "print(finalclasses[finalclasses>3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#builds features from top of csv file for designated number of lines\n",
    "#returns tuple with ee.featurecollection sized according to num in index 0 \n",
    "#number of features collected is in position 1\n",
    "def build_features(num) :\n",
    "        i=0\n",
    "        listsamples=[]\n",
    "        while i < num :\n",
    "            lonlat=[fia['LON'][i],fia['LAT'][i]]\n",
    "            thiseventyear= int(fia['INVYR'][i])\n",
    "            if finalclasses[i] > 0:\n",
    "                singlepoint= ee.Feature(ee.Geometry.Point(lonlat),\n",
    "                        {\n",
    "                          \"system:index\": str(len(listsamples)),\n",
    "                          \"plot_class\": finalclasses[i],\n",
    "                          \"label\": \"A\",\n",
    "                          \"event_year\": thiseventyear\n",
    "                        })\n",
    "                listsamples=np.append(listsamples,singlepoint)\n",
    "            if finalclasses[i] < 1 :\n",
    "                chance=float(np.random.rand(1))\n",
    "                if chance > .25 :\n",
    "                    singlepoint= ee.Feature(ee.Geometry.Point(lonlat),\n",
    "                        {\n",
    "                          \"system:index\": str(len(listsamples)),\n",
    "                          \"plot_class\": finalclasses[i],\n",
    "                          \"label\": \"A\",\n",
    "                          \"event_year\": thiseventyear\n",
    "                        })\n",
    "                    listsamples=np.append(listsamples,singlepoint)\n",
    "                if chance < 24.9999999:\n",
    "                    listsamples=listsamples\n",
    "            i=i+1\n",
    "        samples=ee.FeatureCollection(list(listsamples))\n",
    "        return(samples,len(listsamples))\n",
    "output=build_features(3)\n",
    "samples=output[0]\n",
    "numberoffeatures=output[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naip = ee.ImageCollection('USDA/NAIP/DOQQ').select(['R', 'G', 'B'])\n",
    "\n",
    "\n",
    "time_stamp = 'system:time_start'  # image acquisition year\n",
    "radius = 55  # pixels\n",
    "\n",
    "def get_neighbs(feature):\n",
    "    feature_geom = feature.geometry()\n",
    "    feature_naip = naip.filterBounds(feature_geom)\n",
    "    feat_img_year = feature.get('event_year')\n",
    "    search_start = ee.Date.fromYMD(feat_img_year, 1, 1).advance(-1.5, 'year')\n",
    "    search_stop = ee.Date.fromYMD(feat_img_year, 12, 31).advance(1.5, 'year')\n",
    "    this_date_range = ee.DateRange(search_start, search_stop)\n",
    "    feature_naip = feature_naip.filterDate(this_date_range)\n",
    "    def get_this_date_image_list(date): \n",
    "      this_date_naip = feature_naip.filter(ee.Filter.eq(time_stamp, date))\n",
    "      neighbs = this_date_naip.mean().int().neighborhoodToBands(ee.Kernel.square(radius))\n",
    "      neighb_dict = neighbs.reduceRegion(geometry=feature_geom,reducer=ee.Reducer.first(),scale=1)\n",
    "      full_feature = ee.Feature(feature_geom, neighb_dict)\n",
    "      first_image = ee.Image(this_date_naip.first())\n",
    "      feat_dict = {'_SAMPLE_ID': feature.get('system:index'), \n",
    "                   '_LABEL': feature.get('label'), \n",
    "                   '_CLASS': feature.get('plot_class'),\n",
    "                   '_IMG_DATE_IS_MATCH': ee.Date(date).get('year').eq(feat_img_year),\n",
    "                   '_IMG_DATE': ee.Date(date).format('MMM d, y'), \n",
    "                   '_IMG_ID': first_image.get('system:index'),\n",
    "                   '_IMG_RES': first_image.projection().nominalScale()\n",
    "                   }\n",
    "      return full_feature.set(feat_dict)\n",
    "    image_dates = ee.List(feature_naip.distinct(time_stamp).aggregate_array(time_stamp))\n",
    "    image_dates_image_list = image_dates.map(get_this_date_image_list)\n",
    "    full_features = ee.FeatureCollection(image_dates_image_list)\n",
    "    return full_features.filter(ee.Filter.neq('R_0_0', None))\n",
    "\n",
    "\n",
    "sample_reds = samples.map(get_neighbs)\n",
    "export_task = ee.batch.Export.table.toDrive(sample_reds.flatten(), folder='FIA_Training')\n",
    "export_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions used to develop tabular data for samples into images that can be inspected during the model building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def range_scale(x):\n",
    "    \"\"\"Range scale a 1D array.\"\"\"\n",
    "    return (x-min(x))/(max(x)-min(x))\n",
    "\n",
    "def aggregate_ee_reductions_data(csvs_dir, patterns):\n",
    "    \"\"\"Append data for each sample into one large data frame.\"\"\"\n",
    "    every_df = pd.DataFrame()\n",
    "    for file_name in os.listdir(csvs_dir):\n",
    "        matched = all(fnmatch.fnmatch(file_name, p) for p in patterns)\n",
    "        if matched:\n",
    "            file_size = os.path.getsize(os.path.join(csvs_dir, file_name))\n",
    "            if file_size != 1: \n",
    "                this_df = pd.read_csv(os.path.join(csvs_dir, file_name))\n",
    "                every_df = every_df.append(this_df)\n",
    "    return every_df.dropna().reset_index(drop=True)\n",
    "\n",
    "def get_index_of_sorted_bands_and_pixels(table, band_map):\n",
    "    \"\"\"Retrieve indices of the sorted columns (combinations of bands and pixel locations).\"\"\"\n",
    "    col_names = table.columns\n",
    "    channel = [i.split('_')[0] for i in col_names]\n",
    "    x_pix_loc = [i.split('_')[1] for i in col_names]\n",
    "    y_pix_loc = [i.split('_')[2] for i in col_names]\n",
    "    df = pd.DataFrame({'channel':channel, 'x_pix_loc':x_pix_loc, 'y_pix_loc':y_pix_loc})\n",
    "    df = df.replace({'channel': band_map}).convert_objects(convert_numeric=True)\n",
    "    df_sorted = df.sort(['channel', 'y_pix_loc', 'x_pix_loc'], ascending=[True, True, True])\n",
    "    return df_sorted.index\n",
    "\n",
    "def save_tabular_image_data_to_png(table, image_size, bands, pngs_dir,\n",
    "                                   metadata_columns, band_columns, \n",
    "                                   band_map={'R': 0, 'G': 1, 'B': 2, 'QA':3},\n",
    "                                   groups=['training', 'test'], prediction=False):\n",
    "    \"\"\"Loop through each row (sample) in the table and write the data to disk as a PNG.\"\"\"\n",
    "    metadata = table.iloc[:, metadata_columns]\n",
    "    unsorted_pixel_data = table.iloc[:, band_columns]\n",
    "    sort_indices = get_index_of_sorted_bands_and_pixels(unsorted_pixel_data, band_map)\n",
    "    pixel_data = unsorted_pixel_data.iloc[:, sort_indices] \n",
    "    num_image_files = pixel_data.shape[0]\n",
    "    image_group = np.random.choice(2, num_image_files, p=[0.9, 0.1])\n",
    "    row_n = image_size * image_size * bands\n",
    "    dataset = np.ndarray(shape=(num_image_files, image_size, image_size, bands),\n",
    "                         dtype=np.uint8)\n",
    "    for image in range(num_image_files):\n",
    "        image_vals = pixel_data.iloc[image, :]\n",
    "        dataset[image, :, :, band_map['R']] = np.reshape(np.array([image_vals[:row_n/bands]]), \n",
    "                       (image_size, image_size))\n",
    "        dataset[image, :, :, band_map['G']] = np.reshape(np.array([image_vals[row_n/bands:row_n/bands*2]]), \n",
    "                       (image_size, image_size))\n",
    "        dataset[image, :, :, band_map['B']] = np.reshape(np.array([image_vals[row_n/bands*2:row_n/bands*3]]), \n",
    "                       (image_size, image_size))\n",
    "        image_coords = yaml.load(metadata.ix[image, '.geo'])['coordinates']\n",
    "        #coords_string = '(' + str(image_coords[1]) + ', ' + str(image_coords[0]) + ')'\n",
    "        imageclass=str(metadata['_CLASS'][int(image)])\n",
    "        if prediction:\n",
    "            png_name = 'record ' + str(image) + ' ' + imageclass + '.png'\n",
    "            group_dir = 'fia_unknown'\n",
    "            image_dir = os.path.join(pngs_dir, group_dir)\n",
    "        else:\n",
    "            image_year = metadata.ix[image, '_IMG_DATE']\n",
    "            record_id = str(int(metadata.ix[image, '_SAMPLE_ID']))\n",
    "            png_name = 'record ' + record_id + ' ' + image_year + ' ' + imageclass + '.png'\n",
    "            group_dir = groups[image_group[image]]\n",
    "            image_dir = os.path.join(pngs_dir, group_dir, metadata.ix[image, '_LABEL'])\n",
    "        if not os.path.exists(image_dir):\n",
    "            os.makedirs(image_dir)\n",
    "#        print(image_dir)\n",
    "#       print(os.path.exists(image_dir))\n",
    "        plt.imsave(os.path.join(image_dir, png_name), dataset[image, :, :, 0:bands])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 36972)\n"
     ]
    }
   ],
   "source": [
    "ee_reds = pd.read_csv('sample_context_55_pixel_radius.csv')\n",
    "\n",
    "print(ee_reds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'system:index', u'B_-10_-1', u'B_-10_-10', u'B_-10_-11', u'B_-10_-12',\n",
      "       u'B_-10_-13', u'B_-10_-14', u'B_-10_-15', u'B_-10_-16', u'B_-10_-17',\n",
      "       ...\n",
      "       u'R_9_8', u'R_9_9', u'_CLASS', u'_IMG_DATE', u'_IMG_DATE_IS_MATCH',\n",
      "       u'_IMG_ID', u'_IMG_RES', u'_LABEL', u'_SAMPLE_ID', u'.geo'],\n",
      "      dtype='object', length=36972)\n",
      "[0, 36971, 36969, 36970, 36965, 36966, 36967, 36968, 36964]\n",
      "111.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:24: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:25: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "col_names = ee_reds.columns\n",
    "radius=int(55)\n",
    "print(col_names)\n",
    "metadata_cols = ['system:index', '.geo', '_LABEL', '_SAMPLE_ID',\n",
    "                 '_IMG_DATE', '_IMG_DATE_IS_MATCH', '_IMG_ID', '_IMG_RES','_CLASS']\n",
    "metadata_indices = [col_names.get_loc(x) for x in metadata_cols]\n",
    "print(metadata_indices)\n",
    "band_indices = [x for x in range(ee_reds.shape[1]) if x not in metadata_indices]\n",
    "print(math.sqrt(len(band_indices)/3))\n",
    "\n",
    "save_tabular_image_data_to_png(ee_reds, image_size=radius*2+1, bands=3, \n",
    "                               pngs_dir='sample_pngs',\n",
    "                               metadata_columns=metadata_indices , band_columns=band_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R_9_8'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=ee_reds.columns.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "681px",
    "right": "20px",
    "top": "71px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
